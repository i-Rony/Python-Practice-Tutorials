{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_cg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    return sigmoid(X.dot(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_reg(theta, X, y, reg_lambda):\n",
    "    m = len(y)\n",
    "    y_zero = (1 - y).dot(np.log(1 - h(X, theta)))\n",
    "    y_one = y.dot(np.log(h(X, theta)))\n",
    "    reg = (reg_lambda / (2 * m)) * sum(theta[1:] ** 2)\n",
    "    J = (-1 / m) * (y_zero + y_one) + reg\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_reg(theta, X, y, reg_lambda):\n",
    "    m = len(y)\n",
    "    reg = (reg_lambda / m) * theta\n",
    "    reg[0] = 0\n",
    "    return ((h(X, theta) - y).dot(X) / m) + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(X, y, num_labels, reg_lambda):\n",
    "    m, n = X.shape\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "    for c in range(1, num_labels + 1):\n",
    "        initial_theta = np.zeros((n + 1, 1))\n",
    "        theta = fmin_cg(f=cost_function_reg, x0=initial_theta, fprime=gradient_reg, args=(X, y == c, reg_lambda), maxiter=100)\n",
    "        all_theta[c - 1, :] = theta.T\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_all(all_theta, X):\n",
    "    m = len(X)\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "    return np.argmax(h(X, all_theta.T), axis=1) + 1 # +1 for the 0 -> 10 transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_samples(X):\n",
    "    size = 20\n",
    "    random_samples = np.random.randint(X.shape[0], size=25)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i, sample in enumerate(random_samples):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[sample].reshape(size, size).T, cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 400 # 20 x 20 pixels\n",
    "num_labels = 10\n",
    "\n",
    "# Loading training data\n",
    "X = np.loadtxt(\"ex3data.csv\", delimiter=',')\n",
    "y = X[:, -1]\n",
    "X = X[:, 0:-1]\n",
    "m = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising some samples\n",
    "plot_random_samples(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing logistic regression cost function with regularisation\n",
    "theta_t = np.array([-2, -1, 1, 2]).T\n",
    "X_t = np.hstack((\n",
    "    np.ones((5, 1)),\n",
    "    np.reshape(np.arange(0.1, 1.6, 0.1), (3, 5)).T\n",
    "))\n",
    "y_t = np.array([1, 0, 1, 0, 1]).T\n",
    "lamdba_t = 3\n",
    "\n",
    "J = cost_function_reg(theta_t, X_t, y_t, lamdba_t)\n",
    "grad = gradient_reg(theta_t, X_t, y_t, lamdba_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Cost: {}\".format(J))\n",
    "print(\"Expected cost: 2.534819\")\n",
    "print(\"Gradients:\")\n",
    "print(grad)\n",
    "print(\"Expected gradients:\")\n",
    "print(\"[0.146561, -0.548558, 0.724722, 1.398003]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training One vs All\n",
    "reg_lambda = 0.1\n",
    "all_theta = one_vs_all(X, y, num_labels, reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = predict_one_vs_all(all_theta, X)\n",
    "\n",
    "print('Training Set Accuracy: {}'.format(np.mean((pred == y)) * 100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}