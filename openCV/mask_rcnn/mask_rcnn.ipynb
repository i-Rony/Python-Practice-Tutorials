{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the COCO class labels the Mask R-CNN was trained on\n",
    "labelsPath = os.path.sep.join(['mask-rcnn-coco', \"object_detection_classes_coco.txt\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the set of colors that will be used when visualizing a given instance segmentation\n",
    "# base path to mask-rcnn directory\n",
    "colorsPath = os.path.sep.join(['mask-rcnn-coco', \"colors.txt\"])\n",
    "COLORS = open(colorsPath).read().strip().split(\"\\n\")\n",
    "COLORS = [np.array(c.split(\",\")).astype(\"int\") for c in COLORS]\n",
    "COLORS = np.array(COLORS, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive the paths to the Mask R-CNN weights and model configuration\n",
    "weightsPath = os.path.sep.join(['mask-rcnn-coco', \"frozen_inference_graph.pb\"])\n",
    "configPath = os.path.sep.join(['mask-rcnn-coco', \"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[INFO] loading Mask R-CNN from disk...\n"
    }
   ],
   "source": [
    "# load our Mask R-CNN trained on the COCO dataset (90 classes) from disk\n",
    "print(\"[INFO] loading Mask R-CNN from disk...\")\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our input image and grab its dimensions\n",
    "image = cv2.imread('C:/Users/Ron/Projects/openCV/mask_rcnn/traffic.jpg')\n",
    "(H, W) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Completed Mask R-CNN in 11.603995 seconds\n"
    }
   ],
   "source": [
    "# construct a blob from the input image and then perform a forward\n",
    "# pass of the Mask R-CNN, giving us (1) the bounding box  coordinates\n",
    "# of the objects in the image along with (2) the pixel-wise segmentation for each specific object\n",
    "blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "(boxes, masks) = net.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "end = time.time()\n",
    "\n",
    "# show timing information and volume information on Mask R-CNN\n",
    "print(\"Completed Mask R-CNN in {:.6f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone our original image so we can draw on it\n",
    "clone = image.copy()\n",
    "# loop over the number of detected objects\n",
    "for i in range(0, boxes.shape[2]):\n",
    "\t# extract the class ID of the detection along with the confidence\n",
    "\t# (i.e., probability) associated with the prediction\n",
    "\tclassID = int(boxes[0, 0, i, 1])\n",
    "\tconfidence = boxes[0, 0, i, 2]\n",
    "\n",
    "\t# filter out weak predictions by ensuring the detected probability\n",
    "\t# is greater than the minimum probability\n",
    "\t# type=float, default=0.5\n",
    "\tif confidence > 0.5:\n",
    "\n",
    "\t\t# scale the bounding box coordinates back relative to the\n",
    "\t\t# size of the image and then compute the width and the height of the bounding box\n",
    "\t\tbox = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\tboxW = endX - startX\n",
    "\t\tboxH = endY - startY\n",
    "\n",
    "\t\t# extract the pixel-wise segmentation for the object, resize\n",
    "\t\t# the mask such that it's the same dimensions of the bounding\n",
    "\t\t# box, and then finally threshold to create a *binary* mask\n",
    "\t\tmask = masks[i, classID]\n",
    "\t\tmask = cv2.resize(mask, (boxW, boxH), interpolation=cv2.INTER_NEAREST)\n",
    "\t\t#minimum threshold for pixel-wise mask segmentation type=float, default=0.3\n",
    "\t\tmask = (mask > 0.3)\n",
    "\n",
    "\t\t# extract the ROI of the image\n",
    "\t\troi = clone[startY:endY, startX:endX]\n",
    "\n",
    "\t\t# now, extract *only* the masked region of the ROI by passing\n",
    "\t\t# in the boolean mask array as our slice condition\n",
    "\t\troi = roi[mask]\n",
    "\n",
    "\t\t# randomly select a color that will be used to visualize this\n",
    "\t\t# particular instance segmentation then create a transparent\n",
    "\t\t# overlay by blending the randomly selected color with the ROI\n",
    "\t\tcolor = random.choice(COLORS)\n",
    "\t\tblended = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
    "\n",
    "\t\t# store the blended ROI in the original image\n",
    "\t\tclone[startY:endY, startX:endX][mask] = blended\n",
    "\n",
    "\t\t# draw the bounding box of the instance on the image\n",
    "\t\tcolor = [int(c) for c in color]\n",
    "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "\t\t# draw the predicted label and associated probability of the\n",
    "\t\t# instance segmentation on the image\n",
    "\t\ttext = \"{}: {:.4f}\".format(LABELS[classID], confidence)\n",
    "\t\tcv2.putText(clone, text, (startX, startY - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-1"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# show the output image\n",
    "cv2.imshow(\"Output\", clone)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}