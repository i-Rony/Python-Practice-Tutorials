{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_cg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset + bit of preprocessing\n",
    "train_images = np.fromfile(\"train-images.idx3-ubyte\", dtype=np.ubyte)\n",
    "train_images = train_images[16:]\n",
    "\n",
    "train_labels = np.fromfile(\"train-labels.idx1-ubyte\", dtype=np.ubyte)\n",
    "train_labels = train_labels[8:]\n",
    "\n",
    "test_images = np.fromfile(\"t10k-images.idx3-ubyte\", dtype=np.ubyte)\n",
    "test_images = test_images[16:]\n",
    "\n",
    "test_labels = np.fromfile(\"t10k-labels.idx1-ubyte\", dtype=np.ubyte)\n",
    "test_labels = test_labels[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape into a matrix having dimensions (60000, 28 * 28)\n",
    "train_images = np.reshape(train_images, (60000, 784))\n",
    "\n",
    "# Reshape into a matrix having dimensions (10000, 28 * 28)\n",
    "test_images = np.reshape(test_images, (10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the network\n",
    "m = len(train_images)\n",
    "input_layer_size = 784\n",
    "num_labels = 10\n",
    "hidden_layer_size = 25\n",
    "reg_lambda = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    g = sigmoid(z)\n",
    "    return g * (1 - g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_propagation(X, theta0, theta1):\n",
    "    m = len(X)\n",
    "\n",
    "    a0 = np.hstack((np.ones((m, 1)), X)).T\n",
    "    z1 = theta0 @ a0\n",
    "    a1 = sigmoid(z1)\n",
    "    a1 = np.vstack((np.ones((1, m)), a1))\n",
    "    z2 = theta1 @ a1\n",
    "    a2 = sigmoid(z2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, theta0, theta1, reg_lambda):\n",
    "    m = len(X)\n",
    "    h = feedforward_propagation(X, theta0, theta1)\n",
    "    J = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    reg = (reg_lambda / (2 * m)) * \\\n",
    "        (np.sum(theta0[:, 2:] ** 2) + np.sum(theta1[:, 2:] ** 2))\n",
    "    return J + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(theta, X, y, reg_lambda, input_layer_size,\n",
    "                     hidden_layer_size, num_labels, cost_or_grad):\n",
    "    m = len(X)\n",
    "\n",
    "    theta0 = np.reshape(theta[0 : hidden_layer_size * (input_layer_size + 1)],\n",
    "        (hidden_layer_size, input_layer_size + 1))\n",
    "    theta1 = np.reshape(theta[hidden_layer_size * (input_layer_size + 1) :],\n",
    "        (num_labels, hidden_layer_size + 1))\n",
    "\n",
    "    a0 = np.hstack((np.ones((m, 1)), X)).T\n",
    "    z1 = theta0 @ a0\n",
    "    a1 = sigmoid(z1)\n",
    "    a1 = np.vstack((np.ones((1, m)), a1))\n",
    "    z2 = theta1 @ a1\n",
    "    h = sigmoid(z2)\n",
    "\n",
    "    J = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    reg = (reg_lambda / (2 * m)) * \\\n",
    "        (np.sum(theta0[:, 2:] ** 2) + np.sum(theta1[:, 2:] ** 2))\n",
    "    \n",
    "    if cost_or_grad == 0:\n",
    "        return J + reg\n",
    "\n",
    "    d2 = h - y\n",
    "    d1 = theta1[:, 1:].T @ d2 * sigmoid_gradient(z1)\n",
    "    delta0 = d1 @ a0.T\n",
    "    delta1 = d2 @ a1.T\n",
    "    theta0[:, 0] = 0\n",
    "    theta1[:, 0] = 0\n",
    "\n",
    "    theta0_grad = (1 / m) * delta0 + (reg_lambda / m) * theta0\n",
    "    theta1_grad = (1 / m) * delta1 + (reg_lambda / m) * theta1\n",
    "\n",
    "    grad = np.append(theta0_grad.flatten(), theta1_grad.flatten())\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cost_accuracy(X_train, y_train, y_train_vector,\n",
    "                        X_test, y_test, y_test_vector,\n",
    "                        theta0, theta1):\n",
    "    predictions = feedforward_propagation(X_train, theta0, theta1)\n",
    "    predictions = np.argmax(predictions, axis=0)\n",
    "    J = cost(X_train, y_train_vector, theta0, theta1, 0)\n",
    "    print(\"Training set cost = {}\".format(J))\n",
    "    print(\"Training set accuracy = {}\".format(np.mean(predictions == y_train) * 100))\n",
    "    predictions = feedforward_propagation(X_test, theta0, theta1)\n",
    "    predictions = np.argmax(predictions, axis=0)\n",
    "    J = cost(X_test, y_test_vector, theta0, theta1, 0)\n",
    "    print(\"Testing set cost = {}\".format(J))\n",
    "    print(\"Testing set accuracy = {}\\n\\n\".format(np.mean(predictions == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_w = input(\"Read parameters from csv? (y/n): \")\n",
    "\n",
    "if r_w == \"y\":\n",
    "    theta0 = np.loadtxt(\"theta0.csv\", delimiter=',')\n",
    "    theta1 = np.loadtxt(\"theta1.csv\", delimiter=',')\n",
    "else:\n",
    "    init_epsilon_0 = np.sqrt(6) / \\\n",
    "        (np.sqrt(input_layer_size) + np.sqrt(hidden_layer_size))\n",
    "    init_epsilon_1 = np.sqrt(6) / \\\n",
    "        (np.sqrt(hidden_layer_size) + np.sqrt(num_labels))\n",
    "    theta0 = np.random.random((hidden_layer_size, input_layer_size + 1)) \\\n",
    "        * 2 * init_epsilon_0 - init_epsilon_0\n",
    "    theta1 = np.random.random((num_labels, hidden_layer_size + 1)) \\\n",
    "        * 2 * init_epsilon_1 - init_epsilon_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "train_labels_vector = np.zeros((num_labels, m))\n",
    "for i in range(m):\n",
    "    train_labels_vector[train_labels[i], i] = 1\n",
    "\n",
    "test_labels_vector = np.zeros((num_labels, len(test_images)))\n",
    "for i in range(len(test_images)):\n",
    "    test_labels_vector[test_labels[i], i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print inital cost and accuracy\n",
    "print(\"Initial cost and accuracy:\")\n",
    "print_cost_accuracy(train_images, train_labels, train_labels_vector,\n",
    "                        test_images, test_labels, test_labels_vector,\n",
    "                        theta0, theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful initialisations\n",
    "theta = np.append(theta0.flatten(), theta1.flatten())\n",
    "my_cost = lambda theta: back_propagation(theta, train_images, train_labels_vector,\n",
    "                                   reg_lambda, input_layer_size,\n",
    "                                   hidden_layer_size, num_labels, 0)\n",
    "my_gradient = lambda theta: back_propagation(theta, train_images, train_labels_vector,\n",
    "                                       reg_lambda, input_layer_size,\n",
    "                                       hidden_layer_size, num_labels, 1)\n",
    "                                       \n",
    "# Train the network\n",
    "periods = 10\n",
    "cost_history = np.zeros(periods + 1)\n",
    "for i in range(periods):\n",
    "    cost_history[i] = cost(train_images, train_labels_vector, theta0, theta1, reg_lambda)\n",
    "    theta = fmin_cg(f=my_cost, x0=theta, fprime=my_gradient, maxiter=50/periods)\n",
    "    \n",
    "    theta0 = np.reshape(theta[0 : hidden_layer_size * (input_layer_size + 1)],\n",
    "        (hidden_layer_size, input_layer_size + 1))\n",
    "    theta1 = np.reshape(theta[hidden_layer_size * (input_layer_size + 1) :],\n",
    "        (num_labels, hidden_layer_size + 1))\n",
    "    print(\"\\n\\nPeriod {}.\".format(i + 1))\n",
    "    print_cost_accuracy(train_images, train_labels, train_labels_vector,\n",
    "                        test_images, test_labels, test_labels_vector,\n",
    "                        theta0, theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history[periods] = cost(train_images, train_labels_vector, theta0, theta1, reg_lambda)\n",
    "\n",
    "plt.title(\"Cost vs Periods\")\n",
    "plt.xlabel(\"Number of periods\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.plot(cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Final cost and accuracy:\")\n",
    "print_cost_accuracy(train_images, train_labels, train_labels_vector,\n",
    "                        test_images, test_labels, test_labels_vector,\n",
    "                        theta0, theta1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}